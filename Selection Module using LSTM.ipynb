{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5de63b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from util.utils import load_data_set, gen_batch_sequence, run_lstm, col_name_encode, create_toy_dataset\n",
    "from model.word_embedding import WordEmbedding\n",
    "\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8a7f0a",
   "metadata": {},
   "source": [
    "## Class for Aggregation Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a58f302",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectionPredictor(nn.Module):\n",
    "    def __init__(self,input_layer,hidden_size,num_layers,max_tok_num,gpu):\n",
    "        super(SelectionPredictor, self).__init__()\n",
    "        self.max_tok_num = max_tok_num\n",
    "        self.sel_lstm = nn.LSTM(input_size=input_layer, hidden_size=hidden_size // 2,\n",
    "                                num_layers=num_layers, batch_first=True,\n",
    "                                dropout=0.3, bidirectional=True)\n",
    "        \n",
    "        self.sel_att = nn.Linear(in_features=hidden_size, out_features=1)\n",
    "        self.sel_col_name_enc = nn.LSTM(input_size=input_layer, hidden_size=hidden_size // 2,\n",
    "                                num_layers=num_layers, batch_first=True,\n",
    "                                dropout=0.3, bidirectional=True)\n",
    "        self.sel_out_K = nn.Linear(hidden_size, hidden_size)\n",
    "        self.sel_out_col = nn.Linear(hidden_size, hidden_size)\n",
    "        self.sel_out = nn.Sequential(nn.Tanh(), nn.Linear(hidden_size, 1))\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "        if(gpu):\n",
    "            self.sel_lstm = self.sel_lstm.to('cuda')\n",
    "            self.sel_col_name_enc = self.sel_col_name_enc.to('cuda')\n",
    "            self.sel_att  = self.sel_att.to('cuda')\n",
    "            self.softmax = self.softmax.to('cuda')\n",
    "            self.sel_out_K  = self.sel_out_K.to('cuda')\n",
    "            self.sel_out_col  = self.sel_out_col.to('cuda')\n",
    "            self.sel_out  = self.sel_out.to('cuda')\n",
    "    \n",
    "    def forward(self,x_input, x_len,col_inp_var, col_name_len, col_len,col_num):\n",
    "        \n",
    "        B = len(x_len)\n",
    "        max_x_len = max(x_len)\n",
    "        \n",
    "        e_col, _ = col_name_encode(col_inp_var, col_name_len, col_len, self.sel_col_name_enc)\n",
    "        h_enc, _ = run_lstm(self.sel_lstm, x_input, x_len) \n",
    "       \n",
    "        att_val = self.sel_att(h_enc)  \n",
    "        att_val = att_val.squeeze()\n",
    "\n",
    "        for idx, num in enumerate(x_len):\n",
    "            if num < max_x_len:\n",
    "                att_val[idx, num:] = -100\n",
    "        \n",
    "        att = self.softmax(att_val)\n",
    "        K_sel = (h_enc * att.unsqueeze(2).expand_as(h_enc)).sum(1)\n",
    "        K_sel_expand = K_sel.unsqueeze(1)\n",
    "\n",
    "        sel_score = self.sel_out(self.sel_out_K(K_sel_expand) + self.sel_out_col(e_col)).squeeze()\n",
    "        max_col_num = max(col_num)\n",
    "        \n",
    "        for idx, num in enumerate(col_num):\n",
    "            if num < max_col_num:\n",
    "                sel_score[idx][num:] = -100\n",
    "\n",
    "        return sel_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2699f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SQL(nn.Module):\n",
    "    def __init__(self, bert_model_name, hidden_size, num_depth ):\n",
    "        super(Seq2SQL,self).__init__()\n",
    "        \n",
    "        self.gpu = torch.cuda.is_available()\n",
    "        if(hidden_size&1!=0):\n",
    "            raise ValueError('hidden size must be even, since this is a bidirectional network')\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.word_emb   = WordEmbedding(bert_model_name)\n",
    "        self.word_emb_size = self.word_emb.bert_model.config.hidden_size\n",
    "        self.selection = SelectionPredictor(input_layer=self.word_emb_size, \n",
    "                                               hidden_size=hidden_size,num_layers = num_depth, max_tok_num = 200,gpu=True)\n",
    "        self.CE = nn.CrossEntropyLoss()\n",
    "        if(torch.cuda.is_available):\n",
    "            self.to('cuda')\n",
    "    \n",
    "    def forward(self,queries, col, col_num):\n",
    "        x_embed, x_lengths = self.word_emb.gen_x_batch(q_batch=queries,col_batch=col)\n",
    "        col_inp_var, col_name_len, col_len = self.word_emb.gen_col_batch(col)\n",
    "\n",
    "        sel_score = self.selection(x_embed.last_hidden_state, x_lengths, col_inp_var, col_name_len, col_len, col_num)\n",
    "\n",
    "        return (sel_score,)\n",
    "    \n",
    "    def loss(self, score, truth_num):\n",
    "        sel_score = score[0]\n",
    "        loss = 0\n",
    "\n",
    "        sel_truth = list(map(lambda x: x[1], truth_num))\n",
    "        data = torch.from_numpy(np.array(sel_truth))\n",
    "        if self.gpu:\n",
    "            sel_truth_var = data.cuda()\n",
    "        else:\n",
    "            sel_truth_var = data\n",
    "\n",
    "        loss += self.CE(sel_score, sel_truth_var.long())\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def gen_query(self, score,query_batch, col_batch, raw_query, raw_col):\n",
    "        sel_score = score[0]\n",
    "        B= len(query_batch)\n",
    "        sel_pred = np.argmax(sel_score.data.cpu().numpy(),axis = 1)\n",
    "        pred_queries = []\n",
    "        for i in range(len(sel_pred)):\n",
    "            pred_queries.append({'sel':sel_pred[i]})\n",
    "\n",
    "        return pred_queries\n",
    "    \n",
    "    def check_accuracy(self, pred_queries, ground_truth_queries):\n",
    "        tot_err = sel_err = 0\n",
    "        for b, (pred_qry, ground_truth_qry) in enumerate(zip(pred_queries, ground_truth_queries)):\n",
    "            good = True\n",
    "\n",
    "            sel_pred = pred_qry['sel']\n",
    "            sel_gt = ground_truth_qry['sel']\n",
    "            if sel_pred != sel_gt:\n",
    "                sel_err += 1\n",
    "                good = False\n",
    "\n",
    "            if good == False:\n",
    "                tot_err += 1\n",
    "\n",
    "        return np.array((sel_err)), tot_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cd3914b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train dataset\n",
      "Loaded 56355 queries and 18585 tables\n",
      "Loading dev dataset\n",
      "Loaded 8421 queries and 2716 tables\n"
     ]
    }
   ],
   "source": [
    "train_queries, train_tables = load_data_set('train')\n",
    "val_queries, val_tables = load_data_set('dev')\n",
    "\n",
    "train_queries, train_tables = create_toy_dataset(train_queries, train_tables,5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfe9d7e",
   "metadata": {},
   "source": [
    "## Function for Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0e63473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_train(model, optimizer,batch_size, sql_queries, table_data):\n",
    "    model.train()\n",
    "    num_queries = len(sql_queries)\n",
    "    perm = np.random.permutation(num_queries)\n",
    "    cumulative_loss = 0.0\n",
    "    start = 0\n",
    "\n",
    "    while start< num_queries:\n",
    "        end = start + batch_size if start + batch_size < len(perm) else len(perm)\n",
    "\n",
    "        q_seq, col_seq, col_num, ans_seq, query_seq, ground_truth_cond_seq, raw_data = \\\n",
    "            gen_batch_sequence(sql_queries, table_data, perm, start, end)\n",
    "        \n",
    "        score = model.forward(q_seq, col_seq,col_num)\n",
    "        loss = model.loss(score,ans_seq)\n",
    "        cumulative_loss += loss.data.cpu().numpy() * (end - start)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        start = end\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cbef9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch_query(sql_data, idx, start, end):\n",
    "    query_gt = []\n",
    "    table_id = []\n",
    "    for i in range(start,end):\n",
    "        query_gt.append(sql_data[idx[i]]['sql'])\n",
    "        table_id.append(sql_data[idx[i]]['table_id'])\n",
    "    return query_gt, table_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16db0a4",
   "metadata": {},
   "source": [
    "## Function for Finding Accuracy of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36a7f5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_acc(model, batch_size, sql_data, table_data, save_results = False):\n",
    "    model.eval()\n",
    "    perm = list(range(len(sql_data)))\n",
    "    start = 0\n",
    "    one_acc_num = 0.0\n",
    "    tot_acc_num = 0.0\n",
    "    while start < len(sql_data):\n",
    "        end = start + batch_size if start + batch_size < len(perm) else len(perm)\n",
    "\n",
    "        q_seq, col_seq, col_num, ans_seq, query_seq, ground_truth_cond_seq, raw_data =\\\n",
    "            gen_batch_sequence(sql_data, table_data, perm, start, end)\n",
    "        \n",
    "        raw_q_seq = [x[0] for x in raw_data]\n",
    "        raw_col_seq = [x[1] for x in raw_data]\n",
    "        \n",
    "        query_gt, table_ids = generate_batch_query(sql_data, perm, start, end)\n",
    "        ground_truth_sel_seq = [x[1] for x in ans_seq]\n",
    "        \n",
    "        score = model.forward(q_seq, col_seq, col_num)\n",
    "        pred_queries = model.gen_query(score, q_seq, col_seq,\n",
    "                                       raw_q_seq, raw_col_seq)\n",
    "        one_err, tot_err = model.check_accuracy(pred_queries, query_gt)\n",
    "        \n",
    "        one_acc_num += (end - start - one_err)\n",
    "        tot_acc_num += (end - start - tot_err)\n",
    "        \n",
    "        start = end\n",
    "        \n",
    "    return tot_acc_num/ len(sql_data), one_acc_num/len(sql_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8d75f5",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbf82d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 1e-6\n",
    "TRAINING_EPOCHS = 20\n",
    "BATCH_SIZE = 128\n",
    "    \n",
    "model = Seq2SQL('bert-base-uncased',100,2)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8e5c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_loses = []\n",
    "training_accuracies = []\n",
    "i = 0;\n",
    "for i in range(TRAINING_EPOCHS):\n",
    "    print(f\"Epoch {i+1}\")\n",
    "\n",
    "    epoch_loss = epoch_train(model, optimizer, BATCH_SIZE, train_queries, train_tables)\n",
    "    epoch_loses.append(epoch_loss)\n",
    "\n",
    "    print(f\"Loss : {epoch_loss}\")\n",
    "\n",
    "    training_accuracy = epoch_acc(model, BATCH_SIZE, train_queries, train_tables)\n",
    "    training_accuracies.append(training_accuracy)\n",
    "    print(training_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279b477c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curve(x_item, y_item, item_name, dataLength, format='png'):\n",
    "    \n",
    "#     y = list(i.data.cpu().numpy().tolist() for i in item)\n",
    "#     x = list(range(TRAINING_EPOCHS))\n",
    "    if isinstance(x_item, GeneratorType):\n",
    "        x_item = list(x_item)\n",
    "    if isinstance(x_item, int):\n",
    "        x_item = list(range(x_item))\n",
    "    plt.plot(x_item, y_item)\n",
    "\n",
    "    plt.xlabel(\"EPOCHS\")\n",
    "    plt.ylabel(item_name)\n",
    "\n",
    "    #plt.show()\n",
    "    time = datetime.now()\n",
    "    day_time_str= time.strftime(\"%H%M%S-%d%m%Y\")\n",
    "    \n",
    "    plt.savefig(f'./Graphs/{day_time_str}_{len(y_item)}EP_{dataLength}trainingqueries_{item_name}.{format}',dpi=300, format=format)\n",
    "    plt.show()\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84d283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossList = list(i.data.cpu().numpy().tolist() for i in epoch_loses)\n",
    "accuracy = list(x for x,y in training_accuracies)\n",
    "plot_curve(TRAINING_EPOCHS, lossList,\"Loss\",len(train_queries),format='svg')\n",
    "plot_curve(range(TRAINING_EPOCHS), accuracy,\"Accuracy\",len(train_queries),format='svg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
